"""
Test cost calculation accuracy.

This script validates that LLM and WhatsApp cost calculations are accurate
and that cost tracking and alerting work correctly.
"""

import sys
import os
# Add parent directory to Python path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from shared.observability_cost import CostCalculator, SessionCostAggregator
from typing import Dict, Any, List, Tuple
import json


class CostCalculationTester:
    """Test cost calculation accuracy."""
    
    def __init__(self):
        self.calculator = CostCalculator()
        self.aggregator = SessionCostAggregator()
        self.test_results = []
    
    def run_all_tests(self) -> bool:
        """Run all cost calculation tests."""
        print("üßÆ Starting Cost Calculation Tests")
        print("=" * 60)
        
        # Test 1: Gemini 1.5 Flash costs
        print("\n1Ô∏è‚É£ Testing Gemini 1.5 Flash cost calculations...")
        self._test_gemini_flash_costs()
        
        # Test 2: Other model costs
        print("\n2Ô∏è‚É£ Testing other model cost calculations...")
        self._test_other_model_costs()
        
        # Test 3: WhatsApp message costs
        print("\n3Ô∏è‚É£ Testing WhatsApp message cost calculations...")
        self._test_whatsapp_costs()
        
        # Test 4: Session aggregation
        print("\n4Ô∏è‚É£ Testing session cost aggregation...")
        self._test_session_aggregation()
        
        # Test 5: Cost alerts
        print("\n5Ô∏è‚É£ Testing cost alert thresholds...")
        self._test_cost_alerts()
        
        # Test 6: Conversation estimation
        print("\n6Ô∏è‚É£ Testing conversation cost estimation...")
        self._test_conversation_estimation()
        
        # Summary
        self._print_summary()
        
        return all(success for success, _ in self.test_results)
    
    def _test_gemini_flash_costs(self):
        """Test Gemini Flash cost calculations (both 1.5 and 2.0 versions)."""
        test_cases = [
            # (model, prompt_tokens, completion_tokens, expected_cost)
            ("gemini-1.5-flash", 1_000_000, 100_000, 0.075 + 0.030),  # $0.105
            ("gemini-2.0-flash", 1_000_000, 100_000, 0.075 + 0.030),  # Same pricing
            ("google-gla:gemini-2.0-flash", 500_000, 50_000, 0.0375 + 0.015),  # $0.0525
            ("gemini-1.5-flash", 100, 50, 0.0000075 + 0.000015),      # $0.0000225
            ("gemini-2.0-flash", 0, 0, 0.0),                           # $0.00
        ]
        
        for model, prompt_tokens, completion_tokens, expected_cost in test_cases:
            cost = self.calculator.calculate_llm_cost(
                model=model,
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens
            )
            
            # Allow for small floating point differences
            success = abs(cost - expected_cost) < 0.000001
            
            if success:
                print(f"‚úÖ {model}: {prompt_tokens:,} + {completion_tokens:,} tokens = ${cost:.6f}")
            else:
                print(f"‚ùå {model}: {prompt_tokens:,} + {completion_tokens:,} tokens = ${cost:.6f} (expected ${expected_cost:.6f})")
            
            self.test_results.append((success, f"{model}: {prompt_tokens}/{completion_tokens}"))
    
    def _test_other_model_costs(self):
        """Test cost calculations for other models."""
        test_cases = [
            ("gemini-2.0-flash", 1000, 1000, (0.075 + 0.30) / 1000),
            ("gpt-4", 1000, 1000, (30.0 + 60.0) / 1000),
            ("gpt-3.5-turbo", 1000, 1000, (0.50 + 1.50) / 1000),
            ("unknown-model", 1000, 1000, 0.0),  # Unknown model should return 0
        ]
        
        for model, prompt_tokens, completion_tokens, expected_cost in test_cases:
            cost = self.calculator.calculate_llm_cost(
                model=model,
                prompt_tokens=prompt_tokens,
                completion_tokens=completion_tokens
            )
            
            success = abs(cost - expected_cost) < 0.000001
            
            if success:
                print(f"‚úÖ {model}: ${cost:.6f} (expected ${expected_cost:.6f})")
            else:
                print(f"‚ùå {model}: ${cost:.6f} (expected ${expected_cost:.6f})")
            
            self.test_results.append((success, f"Model cost: {model}"))
    
    def _test_whatsapp_costs(self):
        """Test WhatsApp message cost calculations."""
        test_cases = [
            # (message_type, country, expected_cost)
            ("service", "US", 0.0),           # Service messages are free
            ("marketing", "US", 0.025),
            ("utility", "US", 0.020),
            ("authentication", "US", 0.015),
            ("marketing", "BR", 0.018),
            ("marketing", "IN", 0.008),
            ("marketing", "ZZ", 0.025),       # Unknown country uses default
        ]
        
        for message_type, country, expected_cost in test_cases:
            cost = self.calculator.calculate_whatsapp_cost(message_type, country)
            
            success = cost == expected_cost
            
            if success:
                print(f"‚úÖ {message_type:15} ({country}): ${cost:.3f}")
            else:
                print(f"‚ùå {message_type:15} ({country}): ${cost:.3f} (expected ${expected_cost:.3f})")
            
            self.test_results.append((success, f"WhatsApp: {message_type}/{country}"))
    
    def _test_session_aggregation(self):
        """Test session cost aggregation."""
        # Clear any existing data
        self.aggregator._session_costs.clear()
        
        session_id = "test_session_123"
        
        # Add some costs
        self.aggregator.add_cost(session_id, 0.05, "llm")
        self.aggregator.add_cost(session_id, 0.03, "llm")
        self.aggregator.add_cost(session_id, 0.025, "whatsapp")
        
        # Get session cost
        session_cost = self.aggregator.get_session_cost(session_id)
        
        tests = [
            (session_cost["total"], 0.105, "Total cost"),
            (session_cost["llm"], 0.08, "LLM cost"),
            (session_cost["whatsapp"], 0.025, "WhatsApp cost"),
        ]
        
        for actual, expected, name in tests:
            success = abs(actual - expected) < 0.000001
            
            if success:
                print(f"‚úÖ {name}: ${actual:.3f}")
            else:
                print(f"‚ùå {name}: ${actual:.3f} (expected ${expected:.3f})")
            
            self.test_results.append((success, f"Session aggregation: {name}"))
    
    def _test_cost_alerts(self):
        """Test cost alert thresholds."""
        # Test high LLM cost alert (threshold: $0.05)
        high_cost_triggered = False
        
        # This should trigger an alert
        cost_metadata = {
            "model": "gpt-4",
            "session_id": "alert_test",
            "operation": "test",
        }
        
        # Simulate high cost
        high_llm_cost = 0.10  # Above $0.05 threshold
        
        # In real implementation, this would check if alert was logged
        # For now, we just verify the calculation
        alert_should_trigger = high_llm_cost > 0.05
        
        print(f"‚úÖ High LLM cost alert logic: ${high_llm_cost:.2f} > $0.05 = {alert_should_trigger}")
        self.test_results.append((True, "Cost alert logic"))
        
        # Test session cost alert (threshold: $1.00)
        session_total = 1.50  # Above $1.00 threshold
        session_alert_should_trigger = session_total > 1.0
        
        print(f"‚úÖ High session cost alert logic: ${session_total:.2f} > $1.00 = {session_alert_should_trigger}")
        self.test_results.append((True, "Session alert logic"))
    
    def _test_conversation_estimation(self):
        """Test conversation cost estimation."""
        estimation = self.calculator.estimate_conversation_cost(
            num_messages=10,
            avg_tokens_per_message=150,
            model="gemini-1.5-flash",
            message_types={
                "service": 8,      # 80% service (free)
                "utility": 1,      # 10% utility
                "marketing": 1,    # 10% marketing
            },
            country="US"
        )
        
        # Expected calculations:
        # Total tokens: 10 * 150 = 1500
        # LLM cost: 750 prompt + 750 completion
        # = (750 * 0.075 + 750 * 0.30) / 1_000_000
        # = 0.00005625 + 0.000225 = $0.00028125
        
        # WhatsApp cost:
        # 8 service @ $0.00 = $0.00
        # 1 utility @ $0.02 = $0.02
        # 1 marketing @ $0.025 = $0.025
        # Total: $0.045
        
        expected_llm = 0.00028125
        expected_whatsapp = 0.045
        expected_total = expected_llm + expected_whatsapp
        
        tests = [
            (estimation["llm_cost"], expected_llm, "LLM cost estimation"),
            (estimation["whatsapp_cost"], expected_whatsapp, "WhatsApp cost estimation"),
            (estimation["total_cost"], expected_total, "Total cost estimation"),
        ]
        
        for actual, expected, name in tests:
            success = abs(actual - expected) < 0.0001
            
            if success:
                print(f"‚úÖ {name}: ${actual:.6f}")
            else:
                print(f"‚ùå {name}: ${actual:.6f} (expected ${expected:.6f})")
            
            self.test_results.append((success, f"Estimation: {name}"))
        
        # Print breakdown
        print(f"\n  Conversation details:")
        print(f"  - Messages: {estimation['num_messages']}")
        print(f"  - Tokens: {estimation['total_tokens']:,}")
        print(f"  - Model: {estimation['model']}")
        print(f"  - WhatsApp breakdown: {json.dumps(estimation['whatsapp_breakdown'], indent=4)}")
    
    def _print_summary(self):
        """Print test summary."""
        print("\n" + "=" * 60)
        print("üìä COST CALCULATION TEST SUMMARY")
        print("=" * 60)
        
        total_tests = len(self.test_results)
        passed_tests = sum(1 for success, _ in self.test_results if success)
        
        # Group results by category
        categories = {}
        for success, test_name in self.test_results:
            category = test_name.split(":")[0]
            if category not in categories:
                categories[category] = []
            categories[category].append((success, test_name))
        
        # Print by category
        for category, results in categories.items():
            print(f"\n{category}:")
            for success, test_name in results:
                status = "‚úÖ" if success else "‚ùå"
                print(f"  {status} {test_name}")
        
        print("\n" + "-" * 60)
        print(f"Total: {passed_tests}/{total_tests} passed")
        
        if passed_tests == total_tests:
            print("\nüéâ All cost calculation tests passed!")
        else:
            print("\n‚ö†Ô∏è Some cost calculation tests failed!")


def main():
    """Main test function."""
    tester = CostCalculationTester()
    
    try:
        success = tester.run_all_tests()
        
        # Test cost formatting
        print("\n\nüí∞ Cost Formatting Tests:")
        print("-" * 30)
        test_amounts = [0.000001, 0.001, 0.01, 0.5, 1.0, 10.50, 100.25]
        for amount in test_amounts:
            formatted = CostCalculator.format_cost(amount)
            print(f"${amount:10.6f} ‚Üí {formatted}")
        
        sys.exit(0 if success else 1)
        
    except Exception as e:
        print(f"\n‚ùå Test failed with error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()